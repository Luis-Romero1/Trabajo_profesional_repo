{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       " 0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n",
       " 1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n",
       " 2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n",
       " 3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n",
       " 4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n",
       " \n",
       "       s5  ...     s12      s13      s14     s15   s16  s17   s18    s19  \\\n",
       " 0  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03  392  2388  100.0   \n",
       " 1  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03  392  2388  100.0   \n",
       " 2  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03  390  2388  100.0   \n",
       " 3  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03  392  2388  100.0   \n",
       " 4  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03  393  2388  100.0   \n",
       " \n",
       "      s20      s21  \n",
       " 0  39.06  23.4190  \n",
       " 1  39.00  23.4236  \n",
       " 2  38.95  23.3442  \n",
       " 3  38.88  23.3739  \n",
       " 4  38.90  23.4044  \n",
       " \n",
       " [5 rows x 26 columns],\n",
       "      0\n",
       " 0  112\n",
       " 1   98\n",
       " 2   69\n",
       " 3   82\n",
       " 4   91)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('PM_train.txt', sep=\" \", header=None)\n",
    "train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\n",
    "train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "train_df = train_df.sort_values(['id','cycle'])\n",
    "\n",
    "test_df = pd.read_csv('PM_test.txt', sep=\" \", header=None)\n",
    "test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
    "test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "truth_df = pd.read_csv('PM_truth.txt', sep=\" \", header=None)\n",
    "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)\n",
    "train_df.head(),truth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.72</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.16</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.97</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.38</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.15</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11934</th>\n",
       "      <td>92</td>\n",
       "      <td>102</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.86</td>\n",
       "      <td>1588.09</td>\n",
       "      <td>1415.99</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.14</td>\n",
       "      <td>2388.14</td>\n",
       "      <td>8125.23</td>\n",
       "      <td>8.4383</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11935</th>\n",
       "      <td>92</td>\n",
       "      <td>103</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.18</td>\n",
       "      <td>1589.53</td>\n",
       "      <td>1411.04</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>520.65</td>\n",
       "      <td>2388.17</td>\n",
       "      <td>8123.80</td>\n",
       "      <td>8.4621</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.78</td>\n",
       "      <td>23.1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11936</th>\n",
       "      <td>92</td>\n",
       "      <td>104</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.67</td>\n",
       "      <td>1585.19</td>\n",
       "      <td>1413.07</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.19</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>8120.47</td>\n",
       "      <td>8.4799</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.57</td>\n",
       "      <td>23.1764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11937</th>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.69</td>\n",
       "      <td>1588.70</td>\n",
       "      <td>1409.71</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.40</td>\n",
       "      <td>2388.16</td>\n",
       "      <td>8124.38</td>\n",
       "      <td>8.4409</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.93</td>\n",
       "      <td>23.2726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11938</th>\n",
       "      <td>92</td>\n",
       "      <td>106</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.81</td>\n",
       "      <td>1591.25</td>\n",
       "      <td>1408.24</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11939 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  cycle  setting1  setting2  setting3      s1      s2       s3  \\\n",
       "0       1      1    0.0023    0.0003     100.0  518.67  643.02  1585.29   \n",
       "1       1      2   -0.0027   -0.0003     100.0  518.67  641.71  1588.45   \n",
       "2       1      3    0.0003    0.0001     100.0  518.67  642.46  1586.94   \n",
       "3       1      4    0.0042    0.0000     100.0  518.67  642.44  1584.12   \n",
       "4       1      5    0.0014    0.0000     100.0  518.67  642.51  1587.19   \n",
       "...    ..    ...       ...       ...       ...     ...     ...      ...   \n",
       "11934  92    102    0.0045   -0.0003     100.0  518.67  642.86  1588.09   \n",
       "11935  92    103    0.0017    0.0001     100.0  518.67  643.18  1589.53   \n",
       "11936  92    104    0.0022    0.0001     100.0  518.67  642.67  1585.19   \n",
       "11937  92    105    0.0016    0.0001     100.0  518.67  642.69  1588.70   \n",
       "11938  92    106    0.0001   -0.0001     100.0  518.67  642.81  1591.25   \n",
       "\n",
       "            s4     s5  ...     s12      s13      s14     s15   s16    s17  \\\n",
       "0      1398.21  14.62  ...  521.72  2388.03  8125.55  8.4052  0.03  392.0   \n",
       "1      1395.42  14.62  ...  522.16  2388.06  8139.62  8.3803  0.03  393.0   \n",
       "2      1401.34  14.62  ...  521.97  2388.03  8130.10  8.4441  0.03  393.0   \n",
       "3      1406.42  14.62  ...  521.38  2388.05  8132.90  8.3917  0.03  391.0   \n",
       "4      1401.92  14.62  ...  522.15  2388.03  8129.54  8.4031  0.03  390.0   \n",
       "...        ...    ...  ...     ...      ...      ...     ...   ...    ...   \n",
       "11934  1415.99  14.62  ...  521.14  2388.14  8125.23  8.4383  0.03  395.0   \n",
       "11935  1411.04  14.62  ...  520.65  2388.17  8123.80  8.4621  0.03  394.0   \n",
       "11936  1413.07  14.62  ...  521.19  2388.19  8120.47  8.4799  0.03  395.0   \n",
       "11937  1409.71  14.62  ...  521.40  2388.16  8124.38  8.4409  0.03  394.0   \n",
       "11938  1408.24   1.00  ...     NaN      NaN      NaN     NaN   NaN    NaN   \n",
       "\n",
       "          s18    s19    s20      s21  \n",
       "0      2388.0  100.0  38.86  23.3735  \n",
       "1      2388.0  100.0  39.02  23.3916  \n",
       "2      2388.0  100.0  39.08  23.4166  \n",
       "3      2388.0  100.0  39.00  23.3737  \n",
       "4      2388.0  100.0  38.99  23.4130  \n",
       "...       ...    ...    ...      ...  \n",
       "11934  2388.0  100.0  38.88  23.2669  \n",
       "11935  2388.0  100.0  38.78  23.1652  \n",
       "11936  2388.0  100.0  38.57  23.1764  \n",
       "11937  2388.0  100.0  38.93  23.2726  \n",
       "11938     NaN    NaN    NaN      NaN  \n",
       "\n",
       "[11939 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean     206.310000\n",
       "std       46.342749\n",
       "min      128.000000\n",
       "25%      177.000000\n",
       "50%      199.000000\n",
       "75%      229.250000\n",
       "max      362.000000\n",
       "Name: cycle, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.cycle.value_counts()\n",
    "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
    "rul[[\"cycle\"]].hist()\n",
    "rul[\"cycle\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def findCorrelation(corr, cutoff=0.9, exact=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    corr: pandas dataframe.\n",
    "        A correlation matrix as a pandas dataframe.\n",
    "    cutoff: float, default: 0.9.\n",
    "        A numeric value for the pairwise absolute correlation cutoff\n",
    "    exact: bool, default: None\n",
    "        A boolean value that determines whether the average correlations be \n",
    "        recomputed at each step\n",
    "    \"\"\"\n",
    "    \n",
    "    def _findCorrelation_fast(corr, avg, cutoff):\n",
    "\n",
    "        combsAboveCutoff = corr.where(lambda x: (np.tril(x)==0) & (x > cutoff)).stack().index\n",
    "\n",
    "        rowsToCheck = combsAboveCutoff.get_level_values(0)\n",
    "        colsToCheck = combsAboveCutoff.get_level_values(1)\n",
    "\n",
    "        msk = avg[colsToCheck] > avg[rowsToCheck].values\n",
    "        deletecol = pd.unique(np.r_[colsToCheck[msk], rowsToCheck[~msk]]).tolist()\n",
    "\n",
    "        return deletecol\n",
    "\n",
    "\n",
    "    def _findCorrelation_exact(corr, avg, cutoff):\n",
    "\n",
    "        x = corr.loc[(*[avg.sort_values(ascending=False).index]*2,)]\n",
    "\n",
    "        if (x.dtypes.values[:, None] == ['int64', 'int32', 'int16', 'int8']).any():\n",
    "            x = x.astype(float)\n",
    "\n",
    "        x.values[(*[np.arange(len(x))]*2,)] = np.nan\n",
    "\n",
    "        deletecol = []\n",
    "        for ix, i in enumerate(x.columns[:-1]):\n",
    "            for j in x.columns[ix+1:]:\n",
    "                if x.loc[i, j] > cutoff:\n",
    "                    if x[i].mean() > x[j].mean():\n",
    "                        deletecol.append(i)\n",
    "                        x.loc[i] = x[i] = np.nan\n",
    "                    else:\n",
    "                        deletecol.append(j)\n",
    "                        x.loc[j] = x[j] = np.nan\n",
    "        return deletecol\n",
    "\n",
    "    \n",
    "    if not np.allclose(corr, corr.T) or any(corr.columns!=corr.index):\n",
    "        raise ValueError(\"correlation matrix is not symmetric.\")\n",
    "        \n",
    "    acorr = corr.abs()\n",
    "    avg = acorr.mean()\n",
    "        \n",
    "    if exact or exact is None and corr.shape[1]<100:\n",
    "        return _findCorrelation_exact(acorr, avg, cutoff)\n",
    "    else:\n",
    "        return _findCorrelation_fast(acorr, avg, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['setting3', 's1', 's5', 's10', 's16', 's18', 's19'], dtype='object')\n",
      "['s11', 's4', 's12', 's7', 's13', 's9']\n"
     ]
    }
   ],
   "source": [
    "#Variables altamente correlacionadas y con baja varianza\n",
    "s=train_df.describe().T\n",
    "s.sort_values(\"std\")\n",
    "print(s[s[\"std\"]<0.0001].index)\n",
    "\n",
    "corr = train_df.drop(s[s[\"std\"]<0.0001].index,axis=1).corr().abs()\n",
    "corr\n",
    "hc = findCorrelation(corr, cutoff=0.75)\n",
    "print(hc)\n",
    "drop_col=list(s[s[\"std\"]<0.0001].index)+list(hc)\n",
    "drop_col\n",
    "\n",
    "train_df=train_df.drop(drop_col,axis=1)#[['s15', 's2', 's8', 's17', 's14', 's20', 's3', 's21']]\n",
    "test_df=test_df.drop(drop_col,axis=1)#[['s15', 's2', 's8', 's17', 's14', 's20', 's3', 's21']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparación de datos \n",
    "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
    "rul.columns = ['id', 'max']\n",
    "train_df = train_df.merge(rul, on=['id'], how='left')\n",
    "train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
    "train_df.drop('max', axis=1, inplace=True)\n",
    "\n",
    "w1 = 15\n",
    "w0 = 90\n",
    "train_df['label1'] = np.where((train_df['RUL'] <= w1+2) & (train_df['RUL'] >= w1-4), 1, 0 )\n",
    "train_df['label2'] = np.where(train_df['RUL'] <= w0, 1, 0 )\n",
    "train_df[\"aux\"]=np.where((train_df['RUL'] < w1-4) , 1, 0 )\n",
    "train_df=train_df[train_df[\"aux\"]==0].drop(\"aux\",axis=1)\n",
    "\n",
    "\n",
    "# MinMax normalization (from 0 to 1)\n",
    "train_df['cycle_norm'] = train_df['cycle']\n",
    "explor=train_df.copy()\n",
    "cols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=train_df.index)\n",
    "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "train_df = join_df.reindex(columns = train_df.columns)\n",
    "\n",
    "train_df=train_df[[\"id\",\"label1\",\"cycle_norm\",'s15', 's2', 's8', 's17', 's14', 's20', 's3', 's21']]\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable\n",
       "s15    62\n",
       "s2     56\n",
       "s8     51\n",
       "s14    44\n",
       "s17    27\n",
       "s3     26\n",
       "s20    20\n",
       "s21    14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparación para importancia de valores\n",
    "explorz=pd.concat([explor[explor[\"label1\"]==1].groupby(\"id\",as_index=False).mean(),explor[explor[\"label1\"]==0].groupby(\"id\",as_index=False).mean()]).sort_values(\"id\")\n",
    "explorz=explorz.drop([\"cycle_norm\"],axis=1)\n",
    "explorz1=explorz[explorz[\"label1\"]==1].melt(\"id\",explorz.drop([\"id\",\"label1\"],axis=1)).merge(explorz[explorz[\"label1\"]==0].melt(\"id\",explorz.drop([\"id\",\"label1\"],axis=1)),on=[\"id\",\"variable\"])\n",
    "explorz1[\"change\"]=abs(1-explorz1[\"value_x\"]/explorz1[\"value_y\"])\n",
    "result1=explorz1.sort_values([\"id\",\"change\"],ascending=False)\n",
    "\n",
    "explorz=pd.concat([train_df[train_df[\"label1\"]==1].groupby(\"id\",as_index=False).mean(),train_df[train_df[\"label1\"]==0].groupby(\"id\",as_index=False).mean()]).sort_values(\"id\")\n",
    "explorz=explorz.drop([\"cycle_norm\"],axis=1)\n",
    "explorz1=explorz[explorz[\"label1\"]==1].melt(\"id\",explorz.drop([\"id\",\"label1\"],axis=1)).merge(explorz[explorz[\"label1\"]==0].melt(\"id\",explorz.drop([\"id\",\"label1\"],axis=1)),on=[\"id\",\"variable\"])\n",
    "explorz1[\"change\"]=abs(1-explorz1[\"value_x\"]/explorz1[\"value_y\"])\n",
    "result2=result1.merge(explorz1,on=[\"id\",\"variable\"]).sort_values([\"id\",\"change_y\"],ascending=False)\n",
    "top_var=result2.groupby([\"id\"]).head(3)\n",
    "top_var[\"variable\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s2', 's15', 's8', 's14', 's3', 's17', 's21']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variables con importancia\n",
    "list(top_var[\"variable\"].value_counts().index)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anormal</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s14</th>\n",
       "      <td>8208.770414</td>\n",
       "      <td>8149.030568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s15</th>\n",
       "      <td>8.514860</td>\n",
       "      <td>8.435264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s17</th>\n",
       "      <td>396.248677</td>\n",
       "      <td>393.120117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>643.590881</td>\n",
       "      <td>642.582297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s20</th>\n",
       "      <td>38.440804</td>\n",
       "      <td>38.758334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s21</th>\n",
       "      <td>23.066849</td>\n",
       "      <td>23.247304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>1602.738710</td>\n",
       "      <td>1589.666641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s8</th>\n",
       "      <td>2388.247507</td>\n",
       "      <td>2388.091900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              anormal       normal\n",
       "variable                          \n",
       "s14       8208.770414  8149.030568\n",
       "s15          8.514860     8.435264\n",
       "s17        396.248677   393.120117\n",
       "s2         643.590881   642.582297\n",
       "s20         38.440804    38.758334\n",
       "s21         23.066849    23.247304\n",
       "s3        1602.738710  1589.666641\n",
       "s8        2388.247507  2388.091900"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.variable.value_counts()\n",
    "result3=result2.merge(top_var[[\"id\",\"variable\"]],how=\"inner\",on=[\"id\",\"variable\"])#[result2[\"variable\"]==\"s14\"]\n",
    "result3.groupby(\"variable\").agg({\"value_x_x\":\"mean\",\"value_y_x\":\"mean\"}).rename({\"value_x_x\":\"anormal\",\"value_y_x\":\"normal\"},axis=1)#[result3[\"variable\"]==\"s17\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisd\\AppData\\Local\\Temp\\ipykernel_6008\\3923843841.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_var3[\"sort_var\"]=top_var3[\"variable\"].str.extract(\"(\\d+)\").astype(\"int\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variable\n",
       "s2, s8      17\n",
       "s8, s15     17\n",
       "s3, s14     10\n",
       "s14, s15    10\n",
       "s2, s14      6\n",
       "s14, s17     5\n",
       "s2, s15      4\n",
       "s14, s21     4\n",
       "s8, s20      3\n",
       "s15, s17     3\n",
       "s8, s21      3\n",
       "s8, s14      3\n",
       "s3, s8       3\n",
       "s2, s20      2\n",
       "s2, s21      2\n",
       "s20, s21     2\n",
       "s17, s20     1\n",
       "s2, s3       1\n",
       "s3, s20      1\n",
       "s3, s17      1\n",
       "s15, s21     1\n",
       "s15, s20     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resultados de variables importante por combinación\n",
    "top_var3=result2.groupby([\"id\"],as_index=False).head(2)\n",
    "top_var3[\"sort_var\"]=top_var3[\"variable\"].str.extract(\"(\\d+)\").astype(\"int\")\n",
    "top_var3=top_var3.sort_values([\"id\",\"sort_var\"])\n",
    "\n",
    "\n",
    "top_var3.groupby('id')['variable'].agg(', '.join).reset_index()[\"variable\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label1</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>s15</th>\n",
       "      <th>s2</th>\n",
       "      <th>s8</th>\n",
       "      <th>s17</th>\n",
       "      <th>s14</th>\n",
       "      <th>s20</th>\n",
       "      <th>s3</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416710</td>\n",
       "      <td>0.698842</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.248605</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.406446</td>\n",
       "      <td>0.572675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.287494</td>\n",
       "      <td>0.193050</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.493898</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.496577</td>\n",
       "      <td>0.604258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.618578</td>\n",
       "      <td>0.482625</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.327929</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.453508</td>\n",
       "      <td>0.647880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.346653</td>\n",
       "      <td>0.474903</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.376743</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.373075</td>\n",
       "      <td>0.573024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.405812</td>\n",
       "      <td>0.501931</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.318166</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.460639</td>\n",
       "      <td>0.641598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label1  cycle_norm       s15        s2        s8    s17       s14  \\\n",
       "0   1       0    0.000000  0.416710  0.698842  0.411765  0.500  0.248605   \n",
       "1   1       0    0.003636  0.287494  0.193050  0.323529  0.625  0.493898   \n",
       "2   1       0    0.007273  0.618578  0.482625  0.441176  0.625  0.327929   \n",
       "3   1       0    0.010909  0.346653  0.474903  0.382353  0.375  0.376743   \n",
       "4   1       0    0.014545  0.405812  0.501931  0.323529  0.250  0.318166   \n",
       "\n",
       "        s20        s3       s21  \n",
       "0  0.441176  0.406446  0.572675  \n",
       "1  0.598039  0.496577  0.604258  \n",
       "2  0.656863  0.453508  0.647880  \n",
       "3  0.578431  0.373075  0.573024  \n",
       "4  0.568627  0.460639  0.641598  "
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparación de los datos de testeo\n",
    "\n",
    "# MinMax normalization (from 0 to 1)\n",
    "test_df['cycle_norm'] = test_df['cycle']\n",
    "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
    "                            columns=cols_normalize, \n",
    "                            index=test_df.index)\n",
    "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
    "test_df = test_join_df.reindex(columns = test_df.columns)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "#Generar lo necesario para añadir la columna de ciclo\n",
    "rul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\n",
    "rul.columns = ['id', 'max']\n",
    "truth_df.columns = ['more']\n",
    "truth_df['id'] = truth_df.index + 1\n",
    "truth_df['max'] = rul['max'] + truth_df['more']\n",
    "truth_df.drop('more', axis=1, inplace=True)\n",
    "\n",
    "# generate RUL for test data\n",
    "test_df = test_df.merge(truth_df, on=['id'], how='left')\n",
    "test_df['RUL'] = test_df['max'] - test_df['cycle']\n",
    "test_df.drop('max', axis=1, inplace=True)\n",
    "\n",
    "# generate label columns w0 and w1 for test data\n",
    "test_df['label1'] = np.where((test_df['RUL'] <= w1+2) & (test_df['RUL'] >= w1-4), 1, 0 )\n",
    "test_df['label2'] = test_df['label1']\n",
    "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
    "test_df[\"aux\"]=np.where((test_df['RUL'] < w1-4) , 1, 0 )\n",
    "test_df=test_df[test_df[\"aux\"]==0].drop(\"aux\",axis=1)\n",
    "\n",
    "test_df=test_df[[\"id\",\"label1\",\"cycle_norm\",'s15', 's2', 's8', 's17', 's14', 's20', 's3', 's21']]\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#herramientas para hacer un grid search\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten , Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras import backend as K\n",
    "from random import sample\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "# univariate lstm example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import random\n",
    "import itertools\n",
    "import tensorflow.compat.v1 as tf\n",
    "import random\n",
    "\n",
    "\n",
    "def train_test_split(data, n_test=20):\n",
    "\trandom.seed(0)\n",
    "\tind=random.sample(range(1, 100), n_test)\n",
    "\treturn data[~data[\"id\"].isin(ind)], data[data[\"id\"].isin(ind)]\n",
    "\t\n",
    "\n",
    "def difference(data, order):\n",
    "\treturn (data-data.shift(order)).dropna(axis=0,how=\"any\")\n",
    "\n",
    "def dataset_train(train1,nam_col=\"label1\"):\n",
    "  \n",
    "\tout_seq = array(train1[nam_col])\n",
    "\tout_seq = out_seq.reshape((len(out_seq), 1))\n",
    "\n",
    "\tcount=1\n",
    "\tfor i in train1.columns:\n",
    "\t\t\n",
    "\t\tin_seq=array(train1[i])\n",
    "\t\tin_seq = in_seq.reshape((len(in_seq), 1))\n",
    "\t\tif count==1:\n",
    "\t\t\tdataset=np.hstack((in_seq,out_seq))\n",
    "\t\t\tcount+=1\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tdataset=np.hstack((in_seq,dataset))\n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        \n",
    "        if out_end_ix > len(sequences):\n",
    "           \n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        if out_end_ix==len(sequences)-4:\n",
    "            X=random.sample(X,30)\n",
    "            y=random.sample(y,30)\n",
    "        else:\n",
    "            pass\t\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "def split_sequences_fin(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "       \n",
    "        if out_end_ix > len(sequences):\n",
    "            #print(\"ya\")\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        \t\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "\t\n",
    "\tn_input, n_filters, n_kernel, n_epochs, n_batch, n_diff, optimizer1,learn_rate, init_mode, activation1 = config\n",
    "\tprint(config)\n",
    "\tprint(train.columns)\n",
    "\t\n",
    "\tcount=0\n",
    "\t\n",
    "\tfor i in train[\"id\"].unique():\n",
    "\t\ttraina_aux=train[train[\"id\"]==i]\n",
    "\t\t\n",
    "\t\n",
    "\t\ttraina=traina_aux.drop(\"id\",axis=1)\n",
    "\t\n",
    "\t\ttraina=dataset_train(traina)\n",
    "\t\n",
    "\t\ttraina_x, traina_y = split_sequences(traina, n_input,1)\n",
    "\t\n",
    "\t\t\n",
    "\t\tif count==0:\n",
    "\t\t\ttrain_x,train_y=(traina_x,traina_y)\n",
    "\t\telse:\t\n",
    "\t\t\ttrain_x=np.concatenate((traina_x,train_x))\n",
    "\t\t\ttrain_y=np.concatenate((traina_y,train_y))\n",
    "\t\tcount=count+1\n",
    "\n",
    "\n",
    "\tcount=0\n",
    "\tdata_fin=pd.DataFrame([])\n",
    "\tfor i in train[\"id\"].unique():\n",
    "\t\ttraina_aux=train[train[\"id\"]==i]\n",
    "\t\n",
    "\t\tdata_fin=pd.concat([data_fin,traina_aux.reset_index(drop=True).iloc[n_input-1:]])\n",
    "\t\ttraina=traina_aux.drop(\"id\",axis=1)\n",
    "\t\n",
    "\t\ttraina=dataset_train(traina)\n",
    "\t\t# print(traina)\n",
    "\t\ttraina_x, traina_y = split_sequences_fin(traina, n_input,1)\n",
    "\t\n",
    "\t\tif count==0:\n",
    "\t\t\ttraintot_x,traintot_y=(traina_x,traina_y)\n",
    "\t\telse:\t\n",
    "\t\t\ttraintot_x=np.concatenate((traintot_x,traina_x))\n",
    "\t\t\ttraintot_y=np.concatenate((traintot_y,traina_y))\n",
    "\t\tcount=count+1\n",
    "\n",
    "\tn_features=train_x.shape[2]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation=activation1, input_shape=(n_input, n_features), kernel_initializer=init_mode))\n",
    "\tmodel.add(MaxPooling1D(pool_size=2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mse', optimizer=optimizer1)\n",
    "\tK.set_value(model.optimizer.learning_rate, learn_rate)\n",
    "\t\n",
    "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "\treturn [model, train_x, train_y,traintot_x,traintot_y,data_fin] \n",
    "\n",
    "# forecast with the fit model\n",
    "def model_predict(model, history, config):\n",
    "\t# unpack config\n",
    "\tn_input, _, _, _, _, n_diff, _, _, _, _ = config\n",
    "\t# prepare data\n",
    "\tcorrection = 0.0\n",
    "\tif n_diff > 0:\n",
    "\t\tcorrection = history.iloc[-n_diff,-1]\n",
    "\t\thistory = difference(history, n_diff)\n",
    "\t\n",
    "\n",
    "\tx_input=np.array(history.iloc[-n_input:]).reshape(1,n_input,history.shape[1])\n",
    "\t\n",
    "\tprint(x_input)\n",
    "\tyhat = model.predict(x_input, verbose=0)\n",
    "\tprint(correction + yhat[0])\n",
    "\treturn correction + yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# print(test)\n",
    "\t# fit model\n",
    "\ttry:\n",
    "\t\tmodel = model_fit(train, cfg)[0]\n",
    "\t\t# seed history with training dataset\n",
    "\t\tcount=0\n",
    "\t\t\n",
    "\t\tfor i in test[\"id\"].unique():\n",
    "\t\t\n",
    "\t\t\ttesta=testa_aux.drop(\"id\",axis=1)\n",
    "\t\t\n",
    "\t\t\ttesta=dataset_train(testa)\n",
    "\t\t\t# print(traina)\n",
    "\t\t\ttesta_x, testa_y = split_sequences(testa, n_input,1)\n",
    "\t\t\t# print(traina_y)\n",
    "\t\t\tif count==0:\n",
    "\t\t\t\ttest_x,test_y=(testa_x,testa_y)\n",
    "\t\t\telse:\t\n",
    "\t\t\t\ttest_x=np.concatenate((test_x,testa_x))\n",
    "\t\t\t\ttest_y=np.concatenate((test_y,testa_y))\n",
    "\t\t\tcount=count+1\t\n",
    "\n",
    "\t\tprint(test_x.shape)\n",
    "\t\tyhat = model.predict(test_x, verbose=0)\n",
    "\t\t\n",
    "\t\tfrom sklearn.metrics import f1_score as f1\n",
    "\t\tz1=np.where(yhat>0.5,1,0)\n",
    "\t\t\n",
    "\t\terror=f1(z1,test_y)\n",
    "\t\t\n",
    "\texcept:\n",
    "\t\terror=-1\t\n",
    "\tprint(' > %.3f' % error)\n",
    "\treturn error\n",
    "\n",
    "def model_fit_lstm(train, config):\n",
    "\t\n",
    "\tn_input, n_filters, n_kernel, n_epochs, n_batch, n_diff, optimizer1,learn_rate, init_mode, activation1 = config\n",
    "\tprint(config)\n",
    "\tprint(train.columns)\n",
    "\t\n",
    "\tcount=0\n",
    "\t\n",
    "\tfor i in train[\"id\"].unique():\n",
    "\t\ttraina_aux=train[train[\"id\"]==i]\n",
    "\t\t\n",
    "\t\t\n",
    "\t\ttraina=traina_aux.drop(\"id\",axis=1)\n",
    "\t\t\n",
    "\t\ttraina=dataset_train(traina)\n",
    "\t\t\n",
    "\t\ttraina_x, traina_y = split_sequences(traina, n_input,1)\n",
    "\t\t\n",
    "\t\tif count==0:\n",
    "\t\t\ttrain_x,train_y=(traina_x,traina_y)\n",
    "\t\telse:\t\n",
    "\t\t\ttrain_x=np.concatenate((traina_x,train_x))\n",
    "\t\t\ttrain_y=np.concatenate((traina_y,train_y))\n",
    "\t\tcount=count+1\n",
    "\n",
    "\n",
    "\tcount=0\n",
    "\tdata_fin=pd.DataFrame([])\n",
    "\tfor i in train[\"id\"].unique():\n",
    "\t\ttraina_aux=train[train[\"id\"]==i]\n",
    "\t\n",
    "\t\tdata_fin=pd.concat([data_fin,traina_aux.reset_index(drop=True).iloc[n_input-1:]])\n",
    "\t\ttraina=traina_aux.drop(\"id\",axis=1)\n",
    "\t\n",
    "\t\ttraina=dataset_train(traina)\n",
    "\t\t\n",
    "\t\ttraina_x, traina_y = split_sequences_fin(traina, n_input,1)\n",
    "\t\n",
    "\t\tif count==0:\n",
    "\t\t\ttraintot_x,traintot_y=(traina_x,traina_y)\n",
    "\t\telse:\t\n",
    "\t\t\ttraintot_x=np.concatenate((traintot_x,traina_x))\n",
    "\t\t\ttraintot_y=np.concatenate((traintot_y,traina_y))\n",
    "\t\tcount=count+1\n",
    "\n",
    "\n",
    "\tprint(\"antes de correr el modelo\")\n",
    "\tprint(train_x.shape,train_y.shape)\n",
    "\tn_features=train_x.shape[2]\n",
    "\t\n",
    "\tmodel = Sequential()\n",
    "\t\n",
    "\tmodel.add(LSTM(\n",
    "         input_shape=(n_input, n_features),\n",
    "         units=n_filters,\n",
    "         return_sequences=True))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\n",
    "\tmodel.add(LSTM(\n",
    "\t\t\tunits=int(n_filters/2),\n",
    "\t\t\treturn_sequences=False))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\n",
    "\tmodel.add(Dense(units=1, activation='sigmoid'))\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "\t\t# fit model\n",
    "\n",
    "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "\n",
    "\t\n",
    "\tK.set_value(model.optimizer.learning_rate, learn_rate)\n",
    "\t\n",
    "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "\treturn [model, train_x, train_y,traintot_x,traintot_y,data_fin] \n",
    "\n",
    "def walk_forward_validation_lstm(data, n_test, cfg):\n",
    "\t\n",
    "\tpredictions = list()\n",
    "\t\n",
    "\tn_input, n_filters, n_kernel, n_epochs, n_batch, n_diff, optimizer1,learn_rate, init_mode, activation1 = cfg\n",
    "\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t\n",
    "\tmodel = model_fit_lstm(train, cfg)[0]\n",
    "\t\n",
    "\tcount=0\n",
    "\t\n",
    "\tfor i in test[\"id\"].unique():\n",
    "\t\n",
    "\t\ttesta=testa_aux.drop(\"id\",axis=1)\n",
    "\t\n",
    "\t\ttesta=dataset_train(testa)\n",
    "\t\t\n",
    "\t\ttesta_x, testa_y = split_sequences_fin(testa, n_input,1)\n",
    "\t\t\n",
    "\t\tif count==0:\n",
    "\t\t\ttest_x,test_y=(testa_x,testa_y)\n",
    "\t\telse:\t\n",
    "\t\t\ttest_x=np.concatenate((test_x,testa_x))\n",
    "\t\t\ttest_y=np.concatenate((test_y,testa_y))\n",
    "\t\tcount=count+1\t\n",
    "\t\n",
    "\tprint(test_x.shape)\n",
    "\tyhat = model.predict(test_x, verbose=0)\n",
    "\t\n",
    "\tfrom sklearn.metrics import f1_score as f1\n",
    "\tz1=np.where(yhat>0.5,1,0)\n",
    "\t\n",
    "\terror=f1(z1,test_y)\n",
    "\t\n",
    "\tprint(' > %.3f' % error)\n",
    "\treturn error\n",
    "\n",
    "\n",
    "\n",
    "# score a model, return None on failure\n",
    "def repeat_evaluate(data, config, n_test,tip_mod, n_repeats=5):\n",
    "\t# convert config to a key\n",
    "\tkey = config\n",
    "\t\n",
    "\tif tip_mod==1:\n",
    "\t\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "\t\t\t# summarize score\n",
    "\t\tresult = mean(scores)\n",
    "\telif tip_mod==2:\n",
    "\t\tscores = [walk_forward_validation_lstm(data, n_test, config) for _ in range(n_repeats)]\n",
    "\t\t\t# summarize score\n",
    "\t\tresult = mean(scores)\t\n",
    "\t\t# except:\n",
    "\t# \tresult= np.nan\n",
    "\tprint('> Model[%s] %.3f' % (str(key), result))\n",
    "\treturn (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, tip_mod=1):\n",
    "\t# evaluate configs\n",
    "\tscores = [repeat_evaluate(data, cfg, n_test, tip_mod) for cfg in cfg_list]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores\n",
    "\n",
    "# create a list of configs to try\n",
    "def model_configs():\n",
    "\t# define scope of configs\n",
    "\tn_input = [2,8,16]\n",
    "\tn_filters = [25,50,100,200]#,128]\n",
    "\tn_kernels = [3]#, 5]\n",
    "\tn_epochs = [15,20,30]\n",
    "\tn_batch = [500,2000,8000]#,64]\n",
    "\tn_diff = [0]#, 7]\n",
    "\toptimizer = ['adam', 'Adamax','Adagrad','SGD']#['adam','SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam']\n",
    "\tlearn_rate = [0.001, 0.1]#, 0.01, 0.3\n",
    "\tinit_mode = ['uniform', 'lecun_uniform','normal','glorot_normal']#['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\tactivation = ['linear','relu','softplus', 'tanh']#['relu','softmax', 'softplus', 'softsign', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "\n",
    "\tnum_comb=0.002\n",
    "\tconfigs = list(itertools.product(n_input,n_filters,n_kernels,n_epochs,n_batch,n_diff,optimizer,learn_rate,init_mode,activation))\n",
    "\tif num_comb>1:\n",
    "\t\tconfigs = sample(configs,int(num_comb))\n",
    "\telse:\n",
    "\t\tconfigs = sample(configs,int(len(configs)*num_comb))\n",
    "\tprint('Total configs: %d' % len(configs))\n",
    "\treturn configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correr el modelo\n",
    "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
    "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm', \"label1\",\"id\"]\n",
    "sensor_cols.extend(sequence_cols)\n",
    "sensor_cols=list(set(sensor_cols)-set(drop_col))\n",
    "data=train_df[[\"id\",\"label1\",'s15', 's2', 's8', 's17', 's14', 's20', 's3', 's21']]#[sensor_cols]\n",
    "n_test = 30\n",
    "cfg_list = model_configs()\n",
    "scores = grid_search(data, cfg_list, n_test,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((16, 200, 3, 20, 2000, 0, 'Adagrad', 0.1, 'glorot_normal', 'relu'),\n",
       "  0.940438871473354),\n",
       " ((16, 100, 3, 15, 500, 0, 'Adamax', 0.001, 'uniform', 'relu'),\n",
       "  0.940438871473354),\n",
       " ((16, 50, 3, 20, 500, 0, 'SGD', 0.1, 'uniform', 'relu'), 0.940438871473354),\n",
       " ((16, 25, 3, 20, 500, 0, 'adam', 0.001, 'lecun_uniform', 'relu'),\n",
       "  0.8744454447831134),\n",
       " ((16, 100, 3, 30, 8000, 0, 'Adagrad', 0.1, 'lecun_uniform', 'tanh'),\n",
       "  0.8693494272780754),\n",
       " ((16, 200, 3, 20, 2000, 0, 'Adagrad', 0.1, 'uniform', 'tanh'),\n",
       "  0.7523510971786833),\n",
       " ((16, 100, 3, 20, 500, 0, 'Adamax', 0.001, 'normal', 'softplus'),\n",
       "  0.7420695286396922),\n",
       " ((16, 100, 3, 15, 2000, 0, 'Adamax', 0.001, 'uniform', 'relu'),\n",
       "  0.7420695286396922),\n",
       " ((16, 100, 3, 15, 2000, 0, 'Adamax', 0.001, 'lecun_uniform', 'tanh'),\n",
       "  0.7083554793851894),\n",
       " ((16, 50, 3, 20, 500, 0, 'Adamax', 0.001, 'uniform', 'softplus'),\n",
       "  0.5924027583416229),\n",
       " ((16, 25, 3, 30, 8000, 0, 'SGD', 0.1, 'lecun_uniform', 'relu'),\n",
       "  0.5642633228840125),\n",
       " ((16, 100, 3, 15, 500, 0, 'adam', 0.1, 'glorot_normal', 'linear'),\n",
       "  0.45827817033317875),\n",
       " ((16, 100, 3, 20, 8000, 0, 'Adamax', 0.001, 'uniform', 'relu'),\n",
       "  0.41698841698841704),\n",
       " ((16, 25, 3, 20, 8000, 0, 'Adamax', 0.1, 'uniform', 'linear'),\n",
       "  0.4099089391839243),\n",
       " ((16, 50, 3, 20, 500, 0, 'Adagrad', 0.001, 'glorot_normal', 'linear'),\n",
       "  0.40988959784384454),\n",
       " ((16, 200, 3, 20, 500, 0, 'Adamax', 0.1, 'uniform', 'relu'),\n",
       "  0.18808777429467083),\n",
       " ((16, 25, 3, 30, 8000, 0, 'Adamax', 0.1, 'uniform', 'softplus'),\n",
       "  0.16636587366694014),\n",
       " ((16, 100, 3, 30, 2000, 0, 'Adagrad', 0.001, 'lecun_uniform', 'relu'),\n",
       "  0.06030150753768844),\n",
       " ((16, 50, 3, 15, 8000, 0, 'adam', 0.1, 'uniform', 'softplus'),\n",
       "  0.0178343949044586),\n",
       " ((16, 100, 3, 30, 2000, 0, 'Adagrad', 0.001, 'uniform', 'tanh'), 0.0),\n",
       " ((16, 200, 3, 20, 2000, 0, 'Adagrad', 0.001, 'glorot_normal', 'linear'), 0.0),\n",
       " ((16, 200, 3, 20, 500, 0, 'SGD', 0.001, 'normal', 'relu'), 0.0),\n",
       " ((16, 50, 3, 20, 500, 0, 'SGD', 0.001, 'lecun_uniform', 'relu'), 0.0),\n",
       " ((16, 100, 3, 30, 2000, 0, 'adam', 0.1, 'uniform', 'relu'), 0.0),\n",
       " ((16, 50, 3, 15, 500, 0, 'SGD', 0.001, 'glorot_normal', 'linear'), 0.0),\n",
       " ((16, 100, 3, 15, 500, 0, 'Adamax', 0.1, 'glorot_normal', 'relu'), 0.0),\n",
       " ((16, 200, 3, 30, 2000, 0, 'SGD', 0.001, 'glorot_normal', 'tanh'), 0.0),\n",
       " ((16, 25, 3, 20, 8000, 0, 'SGD', 0.001, 'uniform', 'relu'), 0.0),\n",
       " ((2, 100, 3, 15, 500, 0, 'Adagrad', 0.001, 'glorot_normal', 'softplus'),\n",
       "  -1.0),\n",
       " ((8, 100, 3, 15, 500, 0, 'SGD', 0.1, 'normal', 'linear'), -1.0),\n",
       " ((2, 100, 3, 30, 8000, 0, 'Adamax', 0.001, 'normal', 'relu'), -1.0),\n",
       " ((8, 100, 3, 15, 500, 0, 'Adamax', 0.001, 'lecun_uniform', 'linear'), -1.0),\n",
       " ((2, 100, 3, 30, 500, 0, 'Adagrad', 0.001, 'normal', 'softplus'), -1.0),\n",
       " ((2, 200, 3, 30, 2000, 0, 'Adamax', 0.001, 'uniform', 'linear'), -1.0),\n",
       " ((2, 50, 3, 15, 500, 0, 'adam', 0.1, 'lecun_uniform', 'softplus'), -1.0),\n",
       " ((2, 50, 3, 30, 8000, 0, 'Adagrad', 0.001, 'uniform', 'softplus'), -1.0),\n",
       " ((8, 100, 3, 20, 8000, 0, 'Adagrad', 0.001, 'uniform', 'softplus'), -1.0),\n",
       " ((8, 25, 3, 20, 8000, 0, 'adam', 0.1, 'normal', 'relu'), -1.0),\n",
       " ((8, 50, 3, 15, 2000, 0, 'Adamax', 0.1, 'normal', 'relu'), -1.0),\n",
       " ((8, 25, 3, 15, 2000, 0, 'Adamax', 0.001, 'lecun_uniform', 'relu'), -1.0),\n",
       " ((8, 100, 3, 20, 500, 0, 'Adagrad', 0.001, 'normal', 'softplus'), -1.0),\n",
       " ((8, 25, 3, 30, 2000, 0, 'SGD', 0.1, 'glorot_normal', 'relu'), -1.0),\n",
       " ((2, 200, 3, 20, 2000, 0, 'Adamax', 0.1, 'glorot_normal', 'tanh'), -1.0),\n",
       " ((2, 100, 3, 15, 8000, 0, 'SGD', 0.001, 'uniform', 'softplus'), -1.0),\n",
       " ((8, 100, 3, 20, 8000, 0, 'adam', 0.001, 'uniform', 'tanh'), -1.0),\n",
       " ((2, 50, 3, 30, 2000, 0, 'Adamax', 0.001, 'normal', 'relu'), -1.0),\n",
       " ((8, 25, 3, 30, 2000, 0, 'Adagrad', 0.001, 'uniform', 'linear'), -1.0),\n",
       " ((2, 200, 3, 15, 2000, 0, 'adam', 0.001, 'lecun_uniform', 'relu'), -1.0),\n",
       " ((8, 200, 3, 15, 500, 0, 'Adagrad', 0.1, 'uniform', 'softplus'), -1.0),\n",
       " ((2, 100, 3, 15, 2000, 0, 'SGD', 0.001, 'uniform', 'linear'), -1.0),\n",
       " ((2, 50, 3, 20, 500, 0, 'Adamax', 0.1, 'uniform', 'tanh'), -1.0),\n",
       " ((8, 200, 3, 20, 8000, 0, 'Adagrad', 0.1, 'normal', 'relu'), -1.0),\n",
       " ((8, 100, 3, 15, 8000, 0, 'SGD', 0.1, 'lecun_uniform', 'softplus'), -1.0),\n",
       " ((8, 25, 3, 20, 2000, 0, 'Adagrad', 0.1, 'normal', 'softplus'), -1.0),\n",
       " ((2, 100, 3, 20, 2000, 0, 'Adamax', 0.001, 'lecun_uniform', 'relu'), -1.0),\n",
       " ((2, 50, 3, 15, 8000, 0, 'adam', 0.1, 'normal', 'relu'), -1.0),\n",
       " ((8, 25, 3, 20, 2000, 0, 'Adamax', 0.1, 'normal', 'tanh'), -1.0),\n",
       " ((2, 100, 3, 15, 8000, 0, 'SGD', 0.1, 'uniform', 'relu'), -1.0),\n",
       " ((2, 200, 3, 30, 2000, 0, 'SGD', 0.001, 'glorot_normal', 'relu'), -1.0),\n",
       " ((8, 50, 3, 15, 500, 0, 'Adagrad', 0.001, 'glorot_normal', 'linear'), -1.0),\n",
       " ((2, 50, 3, 20, 8000, 0, 'SGD', 0.1, 'lecun_uniform', 'softplus'), -1.0),\n",
       " ((2, 50, 3, 20, 8000, 0, 'Adamax', 0.1, 'uniform', 'softplus'), -1.0),\n",
       " ((8, 50, 3, 20, 500, 0, 'Adamax', 0.1, 'glorot_normal', 'softplus'), -1.0),\n",
       " ((8, 25, 3, 20, 8000, 0, 'adam', 0.1, 'glorot_normal', 'linear'), -1.0),\n",
       " ((8, 25, 3, 20, 8000, 0, 'SGD', 0.1, 'normal', 'relu'), -1.0),\n",
       " ((8, 25, 3, 20, 500, 0, 'Adagrad', 0.1, 'uniform', 'relu'), -1.0),\n",
       " ((8, 25, 3, 30, 500, 0, 'Adagrad', 0.1, 'lecun_uniform', 'linear'), -1.0),\n",
       " ((2, 25, 3, 15, 500, 0, 'adam', 0.1, 'normal', 'linear'), -1.0),\n",
       " ((2, 100, 3, 30, 500, 0, 'adam', 0.1, 'glorot_normal', 'linear'), -1.0),\n",
       " ((8, 25, 3, 15, 8000, 0, 'Adagrad', 0.1, 'normal', 'softplus'), -1.0),\n",
       " ((2, 100, 3, 20, 8000, 0, 'SGD', 0.1, 'uniform', 'linear'), -1.0),\n",
       " ((2, 100, 3, 20, 500, 0, 'Adagrad', 0.1, 'glorot_normal', 'relu'), -1.0),\n",
       " ((8, 200, 3, 30, 8000, 0, 'Adamax', 0.1, 'uniform', 'softplus'), -1.0),\n",
       " ((2, 100, 3, 15, 8000, 0, 'Adamax', 0.001, 'glorot_normal', 'relu'), -1.0),\n",
       " ((8, 100, 3, 30, 500, 0, 'SGD', 0.001, 'normal', 'softplus'), -1.0),\n",
       " ((2, 200, 3, 20, 500, 0, 'SGD', 0.001, 'normal', 'linear'), -1.0),\n",
       " ((2, 50, 3, 15, 2000, 0, 'adam', 0.1, 'lecun_uniform', 'linear'), -1.0),\n",
       " ((8, 200, 3, 20, 2000, 0, 'adam', 0.001, 'uniform', 'tanh'), -1.0),\n",
       " ((2, 200, 3, 30, 500, 0, 'adam', 0.1, 'glorot_normal', 'relu'), -1.0),\n",
       " ((2, 50, 3, 20, 2000, 0, 'Adagrad', 0.001, 'lecun_uniform', 'linear'), -1.0),\n",
       " ((2, 25, 3, 30, 500, 0, 'Adagrad', 0.001, 'uniform', 'tanh'), -1.0),\n",
       " ((8, 50, 3, 20, 500, 0, 'Adamax', 0.1, 'glorot_normal', 'tanh'), -1.0),\n",
       " ((2, 50, 3, 15, 8000, 0, 'Adamax', 0.1, 'lecun_uniform', 'softplus'), -1.0),\n",
       " ((8, 50, 3, 20, 8000, 0, 'adam', 0.001, 'lecun_uniform', 'tanh'), -1.0),\n",
       " ((8, 100, 3, 20, 8000, 0, 'Adamax', 0.001, 'glorot_normal', 'tanh'), -1.0),\n",
       " ((8, 100, 3, 30, 8000, 0, 'adam', 0.001, 'lecun_uniform', 'linear'), -1.0),\n",
       " ((2, 100, 3, 15, 500, 0, 'adam', 0.001, 'uniform', 'tanh'), -1.0),\n",
       " ((2, 100, 3, 15, 500, 0, 'adam', 0.001, 'uniform', 'linear'), -1.0),\n",
       " ((2, 25, 3, 30, 2000, 0, 'Adamax', 0.1, 'uniform', 'relu'), -1.0),\n",
       " ((2, 50, 3, 20, 8000, 0, 'Adamax', 0.1, 'glorot_normal', 'linear'), -1.0),\n",
       " ((2, 100, 3, 15, 2000, 0, 'Adamax', 0.001, 'glorot_normal', 'relu'), -1.0),\n",
       " ((2, 50, 3, 30, 500, 0, 'Adamax', 0.001, 'normal', 'relu'), -1.0),\n",
       " ((8, 50, 3, 30, 500, 0, 'Adagrad', 0.1, 'glorot_normal', 'linear'), -1.0),\n",
       " ((2, 50, 3, 20, 500, 0, 'adam', 0.001, 'uniform', 'softplus'), -1.0),\n",
       " ((8, 25, 3, 15, 500, 0, 'adam', 0.001, 'uniform', 'relu'), -1.0),\n",
       " ((2, 50, 3, 15, 2000, 0, 'Adamax', 0.1, 'glorot_normal', 'linear'), -1.0)]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort(key=lambda tup: tup[1],reverse=True)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 200, 3, 20, 2000, 0, 'Adagrad', 0.1, 'glorot_normal', 'relu']\n",
      "[16, 200, 3, 20, 2000, 0, 'Adagrad', 0.1, 'glorot_normal', 'relu']\n",
      "Index(['id', 'label1', 'cycle_norm', 's15', 's2', 's8', 's17', 's14', 's20',\n",
      "       's3', 's21'],\n",
      "      dtype='object')\n",
      "77/77 [==============================] - 0s 947us/step\n",
      "121/121 [==============================] - 0s 925us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9433962264150945, 0.8365650969529085)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entrenamiento final\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "scores.sort(key=lambda tup: tup[1],reverse=True)\n",
    "scores\n",
    "n_input=16\n",
    "z=pd.DataFrame([dict(scores).values(),dict(scores).keys()]).T.sort_values(0).head(30)\n",
    "\n",
    "train_f, test_f = train_test_split(data, 30)\n",
    "z=train_f.copy()\n",
    "sco=list(scores[0][0])\n",
    "# sco=list(scores[5][0])\n",
    "# sco=[8,50,3,15,2000,7,\"Adagrad\",0.001,\"glorot_normal\",\"softplus\"]\n",
    "# sco=[8,25,3,50,500,0,\"SGD\",0.1,\"uniform\",\"tanh\"]\n",
    "# sco=[8,50,3,15,2000,0,\"Adagrad\",0.001,\"glorot_normal\",\"softplus\"]\n",
    "# sco= [16,200,3,30,500,0,\"Adamax\",0.001,\"uniform\",\"linear\"]\n",
    "# sco[3]=12\n",
    "# sco[3]=50\n",
    "print(sco)\n",
    "\n",
    "\n",
    "\n",
    "# model = model_fit_lstm(train_f, sco)\n",
    "model = model_fit(train_f, sco)\n",
    "model,train_fx,train_fy,traintot_x,traintot_y,datos_fin_train=model[0],model[1],model[2],model[3],model[4],model[5]\n",
    "\n",
    "count=0\n",
    "\n",
    "data_fin_test=pd.DataFrame([])\n",
    "for i in test_f[\"id\"].unique():\n",
    "\ttesta_aux=test_f[test_f[\"id\"]==i]\n",
    "\tdata_fin_test=pd.concat([data_fin_test,testa_aux])\n",
    "\ttesta=testa_aux.drop(\"id\",axis=1)\n",
    "\ttesta=dataset_train(testa)\n",
    "\ttesta_x, testa_y = split_sequences_fin(testa, n_input,1)\n",
    "\tif count==0:\n",
    "\t\ttestaf_x,testaf_y=(testa_x,testa_y)\n",
    "\telse:\t\n",
    "\t\ttestaf_x=np.concatenate((testa_x,testaf_x))\n",
    "\t\ttestaf_y=np.concatenate((testa_y,testaf_y))\n",
    "\tcount=count+1\t\n",
    "\n",
    "\n",
    "predict=model.predict(train_fx)\n",
    "predict\n",
    "\n",
    "predictt=model.predict(testaf_x)\n",
    "predictt\n",
    "\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "\n",
    "error=precision(np.where(predict>0.5,1,0),train_fy)\n",
    "error\n",
    "f1(np.where(predict>0.5,1,0),train_fy),f1(np.where(predictt>0.5,1,0),testaf_y)#,error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365650969529085"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(np.where(predictt>0.5,1,0),testaf_y)\n",
    "f1(np.where(predictt>0.5,1,0),testaf_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revisión de predicciones\n",
    "pd.set_option('display.max_rows', None)\n",
    "datos_predf=pd.DataFrame({\"Y\":list(testaf_y.reshape(len(testaf_y))),\"Y_pred\":list(np.where(predictt>0.5,1,0).reshape(len(testaf_y)))})\n",
    "datos_predf.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8307692307692308"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_input=16\n",
    "count=0\n",
    "for i in test_df[\"id\"].unique():\n",
    "\n",
    "    testa=test_df[test_df[\"id\"]==i].drop(\"id\",axis=1)\n",
    "    testa=dataset_train(testa)\n",
    "    testa_x, testa_y = split_sequences_fin(testa, n_input,1)\n",
    "    if count==0:\n",
    "        testf_x,testf_y=(testa_x,testa_y)\n",
    "    else:\t\n",
    "        testf_x=np.concatenate((testf_x,testa_x))\n",
    "        testf_y=np.concatenate((testf_y,testa_y))\n",
    "    count=count+1\t\n",
    "\n",
    "\n",
    "predict_val=model.predict(testf_x)\n",
    "error=f1(np.where(predict_val>0.5,1,0),testf_y)\n",
    "error\n",
    "\n",
    "#['s20', 's6', 'setting1', 'setting2', 'label1', 's14', 's8', 's3', 's17',\n",
    "    #    'cycle_norm', 's21', 's2', 's15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6928</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6929</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y  Y_pred\n",
       "1358  1.0       1\n",
       "2752  1.0       1\n",
       "6928  1.0       0\n",
       "6929  1.0       1\n",
       "7272  1.0       1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Z=pd.DataFrame({\"Y\":list(testf_y.reshape(len(testf_y))),\"Y_pred\":list(np.where(predict_val>0.5,1,0).reshape(len(testf_y)))})#.tail(2000)\n",
    "Z[Z[\"Y\"]==1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisión visual de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6120"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.sum(np.where(predict_val>0.5,1,0))\n",
    "np.where(predict_val>0.5,1,0).reshape(len(testf_y))[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción total train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436/436 [==============================] - 3s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13939, 2)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_traintot=model.predict(traintot_x)\n",
    "datos_rev=pd.DataFrame({\"Y\":list(traintot_y.reshape(len(traintot_y))),\"Y_pred\":list(np.where(predict_traintot>0.5,1,0).reshape(len(traintot_y)))})\n",
    "datos_rev.shape\n",
    "f1(datos_rev[\"Y\"],datos_rev[\"Y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label1</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>s15</th>\n",
       "      <th>s2</th>\n",
       "      <th>s8</th>\n",
       "      <th>s17</th>\n",
       "      <th>s14</th>\n",
       "      <th>s20</th>\n",
       "      <th>s3</th>\n",
       "      <th>s21</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.318199</td>\n",
       "      <td>0.410334</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.178181</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.259865</td>\n",
       "      <td>0.574979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022346</td>\n",
       "      <td>0.184302</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.147387</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.434707</td>\n",
       "      <td>0.707539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.151976</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.168508</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.440375</td>\n",
       "      <td>0.794256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027933</td>\n",
       "      <td>0.419777</td>\n",
       "      <td>0.325228</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.232614</td>\n",
       "      <td>0.620155</td>\n",
       "      <td>0.233486</td>\n",
       "      <td>0.807097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>0.265102</td>\n",
       "      <td>0.258359</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.196383</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.269675</td>\n",
       "      <td>0.651477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label1  cycle_norm       s15        s2        s8       s17       s14  \\\n",
       "0   1       0    0.019553  0.318199  0.410334  0.222222  0.250000  0.178181   \n",
       "1   1       0    0.022346  0.184302  0.276596  0.333333  0.333333  0.147387   \n",
       "2   1       0    0.025140  0.399000  0.151976  0.333333  0.416667  0.168508   \n",
       "3   1       0    0.027933  0.419777  0.325228  0.333333  0.333333  0.232614   \n",
       "4   1       0    0.030726  0.265102  0.258359  0.422222  0.250000  0.196383   \n",
       "\n",
       "        s20        s3       s21    Y  Y_pred  \n",
       "0  0.643411  0.259865  0.574979  0.0       0  \n",
       "1  0.705426  0.434707  0.707539  0.0       0  \n",
       "2  0.627907  0.440375  0.794256  0.0       0  \n",
       "3  0.620155  0.233486  0.807097  0.0       0  \n",
       "4  0.713178  0.269675  0.651477  0.0       0  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unir predicciones con valores de la tabla\n",
    "datos_rev1=pd.concat([datos_fin_train.reset_index(drop=True),datos_rev.reset_index(drop=True)],axis=1)\n",
    "datos_rev1[datos_rev1[\"id\"]==1].head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
